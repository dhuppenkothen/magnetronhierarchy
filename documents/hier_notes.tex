\documentclass[a4paper]{artikel3}

\addtolength{\topmargin}{-.5in}
\addtolength{\oddsidemargin}{-.3in}
\addtolength{\evensidemargin}{-.3in}
\addtolength{\textwidth}{0.6in}
\addtolength{\textheight}{1in}

\usepackage[round]{natbib}
\usepackage{amsmath,amssymb,amsbsy,bbm}
\usepackage{graphicx,subfloat,booktabs,url,color}
\usepackage[sc]{mathpazo}
\linespread{1.05}
\usepackage{microtype}

\newcommand{\g}{\,|\,} % ``given''
\newcommand{\te}{\!=\!} % thin equals
\newcommand{\tp}{\!+\!} % thin plus
\newcommand{\tm}{\!-\!} % ...
\newcommand{\ttimes}{\!\times\!} % ...
\newcommand{\bx}{{\bf x}}
\newcommand{\bm}{{\bf m}}
\newcommand{\by}{{\bf y}}
\newcommand{\btheta}{{\boldsymbol{\theta}}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\sth}{^{(s)}}
%\newcommand{\data}{\{\by_m\}}
\newcommand{\data}{Y}

\title{Hierarchical Magnetar modeling across bursts}
\author{--- working notes}
\date{April 2015}

\begin{document}

\maketitle

\subsection*{A hierarchical prior covering energy-duration relationships}

We slightly modify the parameterization of a word model of a spike from our
previous work. Each word is now described by a duration $D$, Amplitude $A$, and
skew $s$.

The duration of a spike is $D = \tau (1\tp s)$, where $\tau$ is the rise time,
and the fall time is $\tau s$.

We have $M$ bursts, where burst $m$ has a set of $N_m$ word parameters $\btheta_m = \{\theta_{n,m}\}_{n=1}^{N_m}$.

The model assumes that each vector of word parameters $\theta$ comes from a
multivariate Gaussian distribution, parameterized in the following way:
\[
    \theta = [\log A,\, \log D,\, \log s]^\top,
    \quad p(\theta\g \alpha) = \N(\theta;\, \bm_\alpha, \Sigma_\alpha).
\]
In previous work, each burst had its own hyperparameters $\alpha_m$, which
apriori came from a fixed broad distribution. Here, we will test two alternative
models. First we will assume that every burst shares the same word distribution,
specified by a common $\alpha$. Second, we will assume that each burst does have
its own hyperparameters $\alpha_m$, but we will learn the distribution that they
come from. We might learn that the $\alpha$'s do take on similar values across
bursts, or that they have some features in common.

Here $\alpha$ has 9 degrees of freedom. We hope that the posterior will be
fairly insensitive to the choice of prior over $\alpha$. Our computations will
use a broad prior, chosen for computational convenience, which we will reweight
to obtain posteriors for different possible choices of prior as necessary.

In our implementation, we set $\alpha$ to contain the mean $m_\alpha$ and the
elements of Cholesky decomposition of $\Sigma_\alpha$ after taking the log of
the diagonal elements. Taking the log of the diagonal makes $\alpha$ both
unconstrained and have a bijection with the parameters of the Gaussian prior
$(m_\alpha,\Sigma_\alpha)$. Other parameterizations may be convenient in other
implementations, for example using the Cholesky decomposition of the inverse
covariance matrix.


\subsection*{Learning energy-duration relationships}

The average energy of a spike\,---\,assuming the energy of photons is unrelated
to spike shape or scale\,---\,is proportional to the area under the curve:
$E = AD = A\tau(1\tp s)$.

If each element of $\theta$ is independent of the others, then the log energy
will be the log duration plus `noise' (an independent log-amplitude for each
burst). Energy will scale with duration, but with multiplicative noise.

Dependencies in $\theta$ can lead to other energy-duration relationships. For
example, if log-amplitude is equal to log-duration plus noise, then the log
energy will be twice the log duration plus noise. Energy will then scale with
duration squared, again with multiplicative noise.


\subsection*{Joint Monte Carlo Inference}

The hyperparameters $\alpha$ can be seen as just parameters of the model, like
the parameters $\{\btheta_m\}$. A standard Monte Carlo inference scheme could be
used to same $S$ joint plausible explanations,
$\{(\alpha^{(s)}, \{\btheta_m^{(s)}\}_{m=1}^M)\}_{s=1}^S$, of the $M$ bursts.
Where each explanation $(\alpha^{(s)}, \{\theta_m^{(s)}\}_{m=1}^M)$ is a sample
from the joint posterior.

We could also consider optimizing the hyperparameters \citep[e.g., Monte Carlo
EM][]{quintana1999}, or optimizing a variational approximation to the posterior
\citep[e.g., adapting][]{hoffman2013}.

Previously, when analyzing bursts independently, we ran each inference as a
separate process, which is `embarrassingly parallel'. We present what is perhaps
the simplest modification to this approach to obtain a posterior over shared
hyperparameters, while continuing to analyse each burst separately, or at least
nearly so.

\subsection*{A Bayesian Committee Machine for Embarrassingly Parallel Monte Carlo}

Here we consider processing each burst $\by_m$ separately. We imagine given each
burst to a separate agent, who infers the hyperparameters given just the small
part of the data that they have access to. The `committee' of these agents, then
combines the results of their inferences to find what we should believe about
the data given all the data $\data=\{\by_m\}$.
\begin{align}
    p(\alpha\g \data) &\,\propto\, p(\alpha)\prod_{m=1}^M p(\by_m\g \alpha) \\
    &\,\propto\, p(\alpha)\prod_{m=1}^M \frac{p_m(\alpha\g \by_m)}{p_m(\alpha)}, \label{eqn:combine}
\end{align}
where $p_m$ gives the personal distribution of an agent using prior
$p_m(\alpha)$ to infer hyperparameters given burst $\by_m$.

\textbf{Density estimation:} Each agent needs to represent their personal
beliefs $p_m(\alpha\g \by_m)$. If they report a mixture of delta functions,
centred on Monte Carlo samples, then the product in \eqref{eqn:combine} will
evaluate to zero for all $\alpha$. Instead, each agent must return a smooth
probability density. They could report a multivariate Gaussian, an
easy-to-implement approximation that gives a multivariate Gaussian posterior.

If each agent has a Gaussian prior, and approximate Gaussian posterior:
\begin{equation}
    p_m(\alpha) = \N(\alpha;\, \bm_m, S_m),
    \qquad p_m(\alpha\g \by_m) \approx \N(\alpha;\, \mu_m, \Sigma_m),
\end{equation}
then our approximate global posterior becomes
\begin{align}
    p(\alpha\g \data) &\,\propto\, p(\alpha)\prod_{m=1}^M \frac{\N(\alpha;\, \mu_m, \Sigma_m)}{\N(\alpha;\, \bm_m, S_m)},\\
                      &\,\propto\, p(\alpha)\,\N(\alpha;\, \mu, \Sigma).
\end{align}
where the global mean and variance are:
\begin{align}
    \Sigma &\,=\, \left[ \sum_{m=1}^M (\Sigma_m^{-1} - S_m^{-1}) \right]^{-1} \\
    \mu &\,=\, \Sigma \sum_{m=1}^M (\Sigma_m^{-1}\mu_m - S_m^{-1}\bm_m) .
\end{align}
It is possible in cases where the Gaussian approximations are poor, especially
if the prior variances are narrow, that the resulting $\Sigma$ isn't positive
definite. In these cases, the agent priors should be set better, and/or more
samples gathered to estimate the agent posteriors.

Given sufficient Monte Carlo samples, and a flexible enough density estimator,
the approximate posterior will tend towards the correct posterior given the
whole dataset. More flexible density estimators include kernel smoothing,
mixtures of Gaussians, or RNADE \citep{uria2013}. However, further MCMC may then
be required to represent the resulting global posterior $p(\alpha\g\data)$.

\textbf{Possible further approximation:} If there were some further
hyperparameters $\beta$, shared by all the bursts, then the posterior over the
original hyperparameters becomes:
\begin{align}
    p(\alpha\g \data) &\,=\, \int p(\alpha, \beta\g Y) \;\mathrm{d}\beta \\
    &\,\neq\, \frac{1}{Z}p(\alpha)\prod_{m=1}^M \frac{\int p_m(\alpha,\beta\g \by_m)\;\mathrm{d}{\beta}}{p_m(\alpha)}. \label{eqn:bcm_wrong}
\end{align}
The second line is not the correct posterior over hyperparameters $\alpha$. If
each agent integrates separately over $\beta$, we do not get the correct
Bayesian inference for a model where they share the same $\beta$. However,
performing inference in this way exists in the literature as an approximation
\citep{tresp2000}. The correct thing to do would be to summarize each agent's
joint beliefs about $(\alpha,\beta)$, and combine. Although that could be
difficult if $\beta$ where high-dimensional.

\textbf{Minibatches:} The data needn't be split into bursts. As indicated in the
previous section, we could perform traditional `batch' processing, where a
single process samples from the posterior given all the data. We choose to split
up the data for computational reasons: to avoid the need for communication
between processes while doing inference. However, we may not need to split up
the data so aggressively. We might have $M$ `minibatches' of data $\by_m$, each
of which contains several bursts.

\textbf{Related work:} There is a lot of related work on combining results from
separate inferences, which remains an active research area. For examples the
Bayesian Committee Machine \citep{tresp2000} contains the above ideas, and
suggests making Gaussian approximations, and the approximation of
Equation~\eqref{eqn:bcm_wrong}. More recently, these ideas have been discussed
explicitly as a way to construct `embarrassingly parallel' Monte Carlo methods
\citep{neiswanger2014}. \citet{wang2014} provide more review and discussion of
these methods, and suggests an alternative view of kernel smoothing to avoid
explicit density estimation. Their method doesn't appear to immediately apply to
the situation here however, where we are simultaneously sampling from joint
posteriors with many nuisance variables $\{\btheta_m\}$.

\subsection*{Alternative: importance reweighting of independent inferences}

An alternative way to combine beliefs about hyperparameters from independent
runs was used by \citet{brewer2014}. Conditioned on a particular setting of the
hyperparameters $\alpha$, the posterior for a burst or minibatch of data $\by_m$
is:
\[
    p(\btheta_m\g \by_m, \alpha) =
        \frac{p(\by_m\g\theta)\,p(\btheta_m\g\alpha)}{p(\by_m\g\alpha)}.
\]
Each agent samples this posterior for a broad reference prior, corresponding to
some hyperparameters $\alpha_0$. The marginal likelihood $p(\alpha\g \by_m)$ for
other $\alpha$'s, is the normalizing constant of the equation above, which can
be estimated (up to a constant) by importance sampling, given the gathered
samples:
\[
p(\by_m\g\alpha) \,\propto\, \mathbb{E}_{\alpha_0}\!\left[\frac{p(\btheta_m\g\alpha)}{p(\btheta_m\g\alpha_0)}\right]
\,\approx\, \frac{1}{S} \sum_{s=1}^S \frac{p(\btheta_m\sth\g\alpha)}{p(\btheta_m\sth\g\alpha_0)}, ~~~
    \btheta_m\sth \sim p(\btheta_m\g \by_m, \alpha_0).
\]

Given that the parameters for a burst $\btheta_m$ is a high-dimensional
object, importance sampling may not work well. Although after preliminary runs,
the reference prior could be refocussed to concentrate the parameters in a
region typical of probable $\alpha$'s.

We wouldn't need to do any form of density estimation. Although each agent
running $S$ Monte Carlo iterations would have to communicate $S$ means and
covariances of posterior $\theta$'s. And the resulting approximate posterior
over $\alpha$ would involve a lot more computation to evaluate pointwise than
the approach of the previous section.

Even if we don't use this approach now, we may wish to use it to estimate
$p(\beta\g \data)$, where $\beta$ are higher-level hyperparameters, specifying
how $\alpha$ is distributed across bursts.


\subsection*{Another alternative: a Rao--Blackwellization}

Now each agent $m$ again samples from both hyperparameters $\alpha$ and its word
parameters $\btheta_m$. Given a normal-inverse Wishart prior over $\alpha$, the
conditional posterior given word parameters for the burst $\btheta_m$ will be normal-inverse
Wishart. If each agent samples $\alpha$ and $\btheta_m$, we can discard the
$\alpha$'s and estimate $p(\alpha\g\by_m)$ as an average of normal-inverse
Wisharts, one for each of the $\btheta_m\sth$'s we sampled.

Under this approach, the agent's posterior looks a bit like a kernel density
estimate based on its $S$ samples. The posterior is approximated with a uniform
mixture of $S$ standard densities (albeit normal-inverse Wisharts). However,
there isn't the same arbitrary blurring of standard kernel density estimation.


\bibliographystyle{abbrvnat} % unsrtnat / abbrvnat
\bibliography{bibs}

\end{document}
